{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e481af",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389ab22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans les arrêtés type \"Agrément de direction\", le titre de l'arrêté correspond à un visa, pas à l'agrément de direction\n",
    "\n",
    "# @TODO ARRETE MODIFICATIF N° pour les arrêtés OCR\n",
    "# Exemple: https://data.iledefrance.fr/pages/publication-des-actes-fiche-detail/?q=identifiant:%22AR2022-372%22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020264b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODONettoyer signatures présidente en OCR <p>.{0,15}?</p><p>Valérie PÉCRESSE</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8982983",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9822be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour une déliberation\n",
    "import platform\n",
    "import os\n",
    "import re\n",
    "import fitz\n",
    "from pdf2docx import parse\n",
    "from typing import Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tempfile import TemporaryDirectory, NamedTemporaryFile\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Pour arrêtés\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "# Pour contrôles open data\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from csv import DictWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf232e",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "abf9d338",
   "metadata": {},
   "outputs": [],
   "source": [
    " if platform.system() == \"Windows\":\n",
    "    #pytesseract.pytesseract.tesseract_cmd = (r\"C:/Program Files/Tesseract-OCR/tesseract.exe\")\n",
    "    # Windows also needs poppler_exe\n",
    "    path_to_poppler_exe = Path(r'C:\\Users\\utilisateur\\Documents\\Python Scripts\\poppler-22.04.0\\Library\\bin')\n",
    "    # Put our output files in a sane place...\n",
    "    out_directory = Path(r\"~\\Desktop\").expanduser()\n",
    "else:\n",
    "    out_directory = Path(\"~\").expanduser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0a17a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_date_ods(date: str) -> str:\n",
    "    \n",
    "    date = date.strip().rstrip(\"\\r\\n\")\n",
    "    \n",
    "    # Convertir en YYYY-MM-DD\n",
    "    annee = date[-4:]\n",
    "    \n",
    "    if (re.search(r\"jan\", date, re.IGNORECASE)):\n",
    "        mois = \"01\"\n",
    "    elif (re.search(r\"vrier\", date, re.IGNORECASE)):\n",
    "        mois = \"02\"\n",
    "    elif (re.search(r\"mars\", date, re.IGNORECASE)):\n",
    "        mois = \"03\"\n",
    "    elif (re.search(r\"avril\", date, re.IGNORECASE)):\n",
    "        mois = \"04\"\n",
    "    elif (re.search(r\"juin\", date, re.IGNORECASE)):\n",
    "        mois = \"06\"\n",
    "    elif (re.search(r\"juil\", date, re.IGNORECASE)):\n",
    "        mois = \"07\"\n",
    "    elif (re.search(r\"ao\", date, re.IGNORECASE)):\n",
    "        mois = \"08\"\n",
    "    elif (re.search(r\"sep\", date, re.IGNORECASE)):\n",
    "        mois = \"09\"\n",
    "    elif (re.search(r\"oct\", date, re.IGNORECASE)):\n",
    "        mois = \"10\"\n",
    "    elif (re.search(r\"nov\", date, re.IGNORECASE)):\n",
    "        mois = \"11\"\n",
    "    elif (re.search(r\"cemb\", date, re.IGNORECASE)):\n",
    "        mois = \"12\"\n",
    "    elif (re.search(r\"mai\", date, re.IGNORECASE)):\n",
    "        mois = \"05\"\n",
    "    else:\n",
    "        mois = \"08\"\n",
    "    \n",
    "    jour = date[0:2].strip().rstrip(\"/-\")\n",
    "    if (len(jour) < 2):\n",
    "        jour = \"0\" + jour\n",
    "    \n",
    "    date = annee + \"-\" + mois + \"-\" + jour\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2e8281a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hocr_to_htmllist(hocr_string, num_page, filename, verbose: bool = False):\n",
    "    \n",
    "    identifiant = \"\"\n",
    "    date_decision = \"\"\n",
    "    date_controle = \"\"\n",
    "    titre = \"\"\n",
    "    titre_is_next = 0\n",
    "    iteration_titre = 0\n",
    "    date_decision_is_next = 0\n",
    "    iteration_date = 0\n",
    "    regex_titre = r\"(?P<titre>(?:portant|de cession|apportant|de désignation|de design|de délég|de nominat|délégu|d'agrément|régissant|emportant|autoris|fixant|relatif|creant|concernant|créant|modifi).{10,150})\"\n",
    "    \n",
    "    # <div class='ocr_page' id='page_1' title='image \"C:\\Users\\UTILIS~1\\AppData\\Local\\Temp\\tess_j3a_34c0_input.JPEG\"; bbox 0 0 4132 5848; ppageno 0'>\n",
    "    #   <div class='ocr_carea' id='block_1_1' title=\"bbox 2781 116 3545 162\">\n",
    "    #     <p class='ocr_par' id='par_1_1' lang='fra' title=\"bbox 2781 116 3545 162\">\n",
    "    #       <span class='ocr_line' id='line_1_1' title=\"bbox 2781 116 3545 162; baseline 0.001 -10; x_size 47; x_descenders 10; x_ascenders 10\">\n",
    "    #          <span class='ocrx_word' id='word_1_1' title='bbox 2781 117 2937 162; x_wconf 96'>Envoyé</span>\n",
    "    #          <span class='ocrx_word' id='word_1_2' title='bbox 2955 126 3004 153; x_wconf 96'>en</span>\n",
    "    \n",
    "    # <body>\n",
    "    # <div class='ocr_page'\n",
    "    # div class='ocr_carea'\n",
    "    soup = BeautifulSoup(hocr_string, 'html.parser')\n",
    "    \n",
    "    paragraphes = []\n",
    "    debut = False\n",
    "    if (num_page > 0):\n",
    "        debut = True\n",
    "    fin = False\n",
    "    \n",
    "    for pages in soup.find_all(\"div\", class_=\"ocr_page\"):\n",
    "        \n",
    "        for paragraph in pages.find_all(\"p\", class_=\"ocr_par\"):\n",
    "            #print(\"MON PARAGRAPH\")\n",
    "            \n",
    "            text = \"\"\n",
    "            for word in paragraph.find_all(\"span\", class_=\"ocrx_word\"):\n",
    "                #print(word.get_text())\n",
    "                #print(word.string)\n",
    "                text += \" \" + word.get_text()\n",
    "            \n",
    "            if (verbose):\n",
    "                print(\"===--TEXT--====\")\n",
    "                print(text)\n",
    "                print(\"===----====\")\n",
    "            \n",
    "            regex_controle_pref = r\"Envoyé en préfecture le ([\\d]{2})/([\\d]{2})/([\\d]{4})\"\n",
    "            detect_controle = re.findall(regex_controle_pref, text)\n",
    "            if (len(detect_controle)):\n",
    "                #date_controle\n",
    "                #print(detect_controle)\n",
    "                date_controle = \"\" + detect_controle[0][2] +\"-\" + detect_controle[0][1] +\"-\" + detect_controle[0][0]\n",
    "            # Acte certifié exécutoire\n",
    "            # Par publication ou notification le JJ/MM/AAAA\n",
    "            # Par transmission au contrôle de Légalité le JJ/MM/AAAA\n",
    "            regex_controle_pref2 = r\"publication\\s+ou\\s+notification\\s+le\\s+([\\d]{2})/([\\d]{2})/([\\d]{4})\"\n",
    "            regex_controle_pref3 = r\"transmission\\s+au\\s+contrôle\\s+de\\s+Légalité\\s+le\\s+([\\d]{2})/([\\d]{2})/([\\d]{4})\"\n",
    "            detect_controle2 = re.findall(regex_controle_pref2, text)\n",
    "            detect_controle3 = re.findall(regex_controle_pref3, text)\n",
    "            if (len(detect_controle2)):\n",
    "                date_controle = \"\" + detect_controle2[0][2] +\"-\" + detect_controle2[0][1] +\"-\" + detect_controle2[0][0]\n",
    "            if (len(detect_controle3)):\n",
    "                date_controle = \"\" + detect_controle3[0][2] +\"-\" + detect_controle3[0][1] +\"-\" + detect_controle3[0][0]\n",
    "            \n",
    "            if (debut == True):\n",
    "                \n",
    "                if (verbose):\n",
    "                    print(\"=DEBUT=\")\n",
    "                \n",
    "                if (titre_is_next == 3):\n",
    "                    # On ajoute au titre la chaîne\n",
    "                    titre = (titre + \" \" + text.replace(\"/\", \"\")).strip().rstrip('\\r\\n,.;')\n",
    "                    titre_is_next = 2\n",
    "                    \n",
    "                cherche_titre = re.search(regex_titre, text.replace(\"/\", \"\"), re.IGNORECASE)\n",
    "                # On introduit la recherche du titre lorsque titre_is_next == 1\n",
    "                if (iteration_titre < 3 and titre_is_next == 1):\n",
    "                    if (cherche_titre is not None and len(cherche_titre.group('titre')) > 10 and titre == \"\"):\n",
    "                        titre = cherche_titre.group('titre').strip().rstrip('\\r\\n,.;')\n",
    "                        titre_is_next = 2\n",
    "                        # Si titre tronqué, titre_is_next = 3\n",
    "                        if (re.search('la Présidente du$', titre) is not None):\n",
    "                            titre_is_next = 3\n",
    "                    else:\n",
    "                        iteration_titre += 1\n",
    "                \n",
    "                # On introduit la recherche de la date lorsque date_is_next == 1\n",
    "                if (iteration_date < 3 and date_decision_is_next == 1 and text.replace(\"/\", \"\").strip().rstrip('\\r\\n') != \"\"):\n",
    "                    \n",
    "                    print(\" --- Date de décision prochaine\")\n",
    "                    regex_date_decision_seule = r\"[DUdu\\s]{2,4}(?P<jour>[\\d]{1,2})[\\s-]{1,2}(?P<mois>[jfmasondJFMASOND][\\w]{2,9})[\\s-]{1,2}(?P<annee>[\\d]{4})\"\n",
    "                    \n",
    "                    cherche_date_decision_seule = re.search(regex_date_decision_seule, text.replace(\"/\", \"\"))\n",
    "                    \n",
    "                    if (cherche_date_decision_seule is not None):\n",
    "                        #print(\" - - - \"+ str(cherche_date_decision_seule))\n",
    "                        date_decision = convertir_date_ods(cherche_date_decision_seule[\"jour\"] + \" \" + cherche_date_decision_seule[\"mois\"] + \" \" + cherche_date_decision_seule[\"annee\"])\n",
    "                        date_decision_is_next = 2\n",
    "                    else:\n",
    "                        iteration_date += 1\n",
    "            \n",
    "            if (debut == False):\n",
    "                #\n",
    "                print(\"Texte replace / : \" + text.replace(\"/\", \"\"))\n",
    "                # ARRETE N° 2020 - A6\n",
    "                regex_complete_init_arrete = r\"A[rêeténARETÊÉN° \\s]{6,15}(?:[ MODIFCATmodifcatnN°\\s]{10,17})?(?P<numero>(?:[\\d]{4}|15|16|17|18|19|20)[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}(?:[\\d]{1,2}\\s?[\\d]{1,2})(?:[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}[\\d]{0,1})?)(?:[DUdu\\s]{2,5}(?P<jour>[\\d]{1,2})[\\s]{1,3}(?P<mois>[A-zÀ-ú]{3,15})[\\s]{1,3}(?P<annee>[\\d]{4}))?(?:[\\s\\:]{0,4})?(?P<titre>(?:[\\s]{0,2}[\\w\\’\\'\\\"'-°àéèëêïöôüûù]{0,25}[\\s]{0,2}[\\d]{0,4}){1,20})?\"\n",
    "                regex_incomplete_arrete = r\"A[rêeténARETÊÉN° \\s]{6,15}(?:[ MODIFCATmodifcatnN°\\s]{10,17})?(?P<numero>(?:[\\d]{4}|15|16|17|18|19|20).{0,7})(?:\\s|-)(?:[DUdu\\s]{2,5}(?P<jour>[\\d]{1,2})[\\s]{1,3}(?P<mois>[A-zÀ-ú]{3,15})[\\s](?P<annee>[\\d]{4}))?(?:[\\s\\:]{0,4})?(?P<titre>(?:[\\s]{0,2}[\\w\\’\\'\\\"'-°àéèëêïöôüûù]{0,25}[\\s]{0,2}[\\d]{0,4}){1,20})?\"\n",
    "                \n",
    "                detect_arrete = re.search(regex_complete_init_arrete, text.replace(\"/\", \"\"))\n",
    "                detect_arrete_incomplet = re.search(regex_incomplete_arrete, text.replace(\"/\", \"\"))\n",
    "                \n",
    "                if (detect_arrete is not None):\n",
    "                    \n",
    "                    date_decision_is_next = 1\n",
    "                    \n",
    "                    print(\"Identifiant trouvé : \" + text)\n",
    "                    # [('2020- © }', '', '', '', \"portant modification de l'arrêté n°16-154 du 30 mai 2016\")]\n",
    "                    \n",
    "                    debut = True\n",
    "                    \n",
    "                    detect_arrete_dict = detect_arrete.groupdict()\n",
    "                    print(\"Match : \", str(detect_arrete_dict))\n",
    "                    \n",
    "                    identifiant = detect_arrete_dict[\"numero\"].replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                    identifiant = prepare_identifiant_from_prepare(identifiant)\n",
    "                    identifiant_compare = prepare_identifiant_from_prepare(filename)\n",
    "                    if(identifiant != identifiant_compare):\n",
    "                        identifiant = identifiant_compare\n",
    "                        print(\"Identifiant non conforme au nom de fichier : \", identifiant, \". L'identifiant du nom de fichier a été récupéré : \", identifiant_compare)\n",
    "                    \n",
    "                    if (all(key in detect_arrete_dict for key in (\"jour\", \"mois\", \"annee\")) and detect_arrete_dict[\"jour\"] is not None and detect_arrete_dict[\"mois\"] is not None and detect_arrete_dict[\"annee\"] is not None):\n",
    "                        \n",
    "                        date_decision_is_next = 2\n",
    "                        \n",
    "                        # [('2021-400', '17', 'décembre', '2021', 'RESTE')]\n",
    "                        date_decision = convertir_date_ods(detect_arrete_dict[\"jour\"] + \" \" + detect_arrete_dict[\"mois\"] + \" \" + detect_arrete_dict[\"annee\"]) # .replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                        identifiant2 = detect_arrete_dict[\"numero\"].replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                        identifiant2 = prepare_identifiant_from_prepare(identifiant2)\n",
    "                        if(identifiant2 != identifiant_compare):\n",
    "                            identifiant2 = identifiant_compare\n",
    "                        identifiant = identifiant2\n",
    "                    \n",
    "                    if (\"titre\" in detect_arrete_dict and len(detect_arrete_dict[\"titre\"]) > 5):\n",
    "                        titre = detect_arrete_dict[\"titre\"].strip().rstrip('\\r\\n')\n",
    "                        print(\"Titre trouvé dans la regex : \", titre)\n",
    "                        titre_is_next = 2\n",
    "                    else:\n",
    "                        titre_is_next = 1\n",
    "                    \n",
    "                elif (detect_arrete_incomplet is not None):\n",
    "                    \n",
    "                    date_decision_is_next = 1\n",
    "                    \n",
    "                    print(\"Identifiant INCOMPLET trouvé : \" + text)\n",
    "                    # print(detect_arrete_incomplet)\n",
    "                    debut = True\n",
    "                    \n",
    "                    detect_arrete_incomplet_dict = detect_arrete_incomplet.groupdict()\n",
    "                    print(\"Match : \", str(detect_arrete_incomplet_dict))\n",
    "                    \n",
    "                    # Récupérer le nom de fichier\n",
    "                    print(\"On utilise le nom de fichier : \", filename)\n",
    "                    identifiant = prepare_identifiant_from_prepare(filename)\n",
    "                    # print(\"Identifiant INCOMPLET trouvé : \", identifiant)\n",
    "                    \n",
    "                    if (all(key in detect_arrete_incomplet_dict for key in (\"jour\", \"mois\", \"annee\")) and detect_arrete_incomplet_dict[\"jour\"] is not None and detect_arrete_incomplet_dict[\"mois\"] is not None and detect_arrete_incomplet_dict[\"annee\"] is not None):\n",
    "                        \n",
    "                        date_decision_is_next = 2\n",
    "                        date_decision = convertir_date_ods(detect_arrete_incomplet_dict[\"jour\"] + \" \" + detect_arrete_incomplet_dict[\"mois\"] + \" \" + detect_arrete_incomplet_dict[\"annee\"]) # .replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                    \n",
    "                    if (\"titre\" in detect_arrete_incomplet_dict and len(detect_arrete_incomplet_dict[\"titre\"]) > 5):\n",
    "                        titre = detect_arrete_incomplet_dict[\"titre\"].strip().rstrip('\\r\\n')\n",
    "                        print(\"Titre trouvé dans la regex : \", titre)\n",
    "                        titre_is_next = 2\n",
    "                    else:\n",
    "                        titre_is_next = 1\n",
    "                \n",
    "                # @TODO inverser les deux blocs\n",
    "                # if debut == True : ...\n",
    "                # Puis if debut == False or ... (voir comment traiter le titre sur le paragraphe suivant l'identifiant c'est-à-dire quand debut == True)\n",
    "                \n",
    "            else :\n",
    "                #if (date_non_trouvee):\n",
    "                #    regex = r\"([\\d]{1,2}) ([A-zÀ-ú]{3,15}) ([\\d]{4})\"\n",
    "                #    date = re.findall(regex, text)\n",
    "                #    if (len(date)):\n",
    "                #        date_decision = date[0][1] + \" \" + date[0][2] + \" \" + date[0][3]\n",
    "                #        date_non_trouvee = False\n",
    "                #print(text.strip())\n",
    "                if (verbose):\n",
    "                    print(\"=DEBUT=\")\n",
    "                \n",
    "                if (\"Envoyé en préfecture\" in text):\n",
    "                    continue\n",
    "                elif (text == \"\"):\n",
    "                    continue\n",
    "                elif (\"Reçu en préfecture le\" in text):\n",
    "                    continue\n",
    "                elif (\"Affiché le\" in text):\n",
    "                    continue\n",
    "                elif (\"ID :\" in text):\n",
    "                    continue\n",
    "                else :\n",
    "                    #print(text)\n",
    "                    paragraphes.append(\"<p>\" + text.strip() + \"</p>\")\n",
    "    \n",
    "    # result_set = soup.find_all(class_=\"ocr_page\")\n",
    "    #print(paragraphes)\n",
    "    return titre, paragraphes, identifiant, date_decision, date_controle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0538895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_ocr(pdf_filename: str = \"\"):\n",
    "    \"\"\"Fonction de reconnaissance d'image, permet de lire le texte image\n",
    "        Argument : le nom du fichier\n",
    "        Retourne :- le texte contenue dans le pdf scanné ou non \n",
    "                  - la date de controle de légalité\n",
    "    \"\"\"\n",
    "    image_file_list = []\n",
    "    text_file = \"\"\n",
    "    titre = \"\"\n",
    "    paragraphes_html = []\n",
    "    identifiant = \"\"\n",
    "    date_decision = \"\"\n",
    "    date_controle = \"\"\n",
    "    \n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        # Create a temporary directory to hold our temporary images.\n",
    "        \"\"\"\n",
    "        Part #1 : Converting PDF to images\n",
    "        \"\"\"\n",
    "        if platform.system() == \"Windows\":\n",
    "            pdf_pages = convert_from_path(pdf_filename, 500, poppler_path=path_to_poppler_exe)\n",
    "        else:\n",
    "            pdf_pages = convert_from_path(pdf_filename, 500)\n",
    "            # Read in the PDF file at 500 DPI\n",
    "        # Iterate through all the pages stored above\n",
    "        for page_enumeration, page in enumerate(pdf_pages, start=1):\n",
    "            # Create a file name to store the image\n",
    "            filename = f\"{tempdir}\\page_{page_enumeration:03}.jpg\"\n",
    "            # Declaring filename for each page of PDF as JPG\n",
    "            page.save(filename, \"JPEG\")\n",
    "            image_file_list.append(filename)\n",
    "        \"\"\"\n",
    "        Part #2 - Recognizing text from the images using OCR\n",
    "        \"\"\"\n",
    "        with NamedTemporaryFile() as output_file:\n",
    "            # Iterate from 1 to total number of pages\n",
    "            num_page = 0\n",
    "            for image_file in image_file_list:\n",
    "\n",
    "                tempimg = Image.open(image_file)\n",
    "                #d = pytesseract.image_to_data(tempimg, lang=\"fra\", output_type=Output.DICT, config=\"hocr\")\n",
    "                d = pytesseract.image_to_pdf_or_hocr(tempimg, lang='fra', extension='hocr').decode('utf-8')\n",
    "                titre_part,liste_paragraphes,identifiant_part,date_decision_part,date_controle_part = parse_hocr_to_htmllist(d, num_page, pdf_filename)\n",
    "                \n",
    "                print(\"Identifiant part : \" + identifiant_part)\n",
    "                print(\"Date decision part : \" + date_decision_part)\n",
    "\n",
    "                paragraphes_html.append(liste_paragraphes)\n",
    "                if (identifiant_part != \"\"):\n",
    "                    identifiant = normalise_identifiant(identifiant_part)\n",
    "                if (date_decision_part != \"\"):\n",
    "                    date_decision = date_decision_part\n",
    "                if (date_controle_part != \"\"):\n",
    "                    date_controle = date_controle_part\n",
    "                if (titre_part != \"\"):\n",
    "                    titre = titre_part\n",
    "                \n",
    "                num_page += 1\n",
    "                \n",
    "                # At the end of the with .. output_file block\n",
    "            # the file is closed after writing all the text.\n",
    "        # At the end of the with .. tempdir block, the\n",
    "        # TemporaryDirectory() we're using gets removed!       \n",
    "    # End of main function!\n",
    "    # print(paragraphes_html)\n",
    "    return titre, text_file, paragraphes_html, identifiant, date_decision, date_controle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7f51cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_publication(mise_en_ligne=\"ok\"):\n",
    "    if mise_en_ligne == 'ok':\n",
    "        date_publication = datetime.today().strftime('%Y-%m-%d')\n",
    "    else :\n",
    "        date_publication = 'Non publiée'\n",
    "    return date_publication\n",
    "\n",
    "def numero_from_identifiant(identifiant: str) -> str:\n",
    "    \"\"\"TODO: à généraliser, utiliser la fonction des Avis CESER\"\"\"\n",
    "    regex_identifiant = r\"([\\d]{4}[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}[\\d]{2,3}(?:[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}[\\d]{0,1})?)\"\n",
    "    cherche_identifiant = re.findall(regex_identifiant, identifiant)\n",
    "    if (len(cherche_identifiant)):\n",
    "        return \"AR \" + cherche_identifiant[0]\n",
    "    return \"\"\n",
    "\n",
    "def normalise_identifiant(identifiant: str) -> str:\n",
    "    \"\"\"Transforme un identifiant sous l'ancien format en identifiant d'arrêté avec AR\"\"\"\n",
    "    regex_identifiant = r\"(?P<annee>[\\d]{4}|15|16|17|18|19|20)\\s*[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}\\s*(?P<numero>[\\d]{2,3})\\s*(?:[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}\\s*(?P<complement>\\d))?\"\n",
    "    cherche_identifiant = re.search(regex_identifiant, identifiant)\n",
    "    if (cherche_identifiant is not None):\n",
    "        ientifiant = \"AR\" + cherche_identifiant.group('annee') + \"-\" + cherche_identifiant.group('numero')\n",
    "        if (cherche_identifiant.group('complement') is not None):\n",
    "            identifiant = identifiant + \"-\" + cherche_identifiant.group('complement')\n",
    "        return identifiant\n",
    "    return \"\"\n",
    "\n",
    "def append_dict_as_row(file_name, dict_of_elem, field_names):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='', encoding=\"utf-8\") as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        dict_writer = DictWriter(write_obj, fieldnames=field_names)\n",
    "        # Add dictionary as wor in the csv\n",
    "        #print(\"=-=-=-\", dict_of_elem)\n",
    "        dict_writer.writerow(dict_of_elem)\n",
    "    return\n",
    "\n",
    "def replacement_numero_article(text: str, verbose: bool = False) -> str:\n",
    "    \"\"\"Fonction qui retourne le texte modifié sur tous les numéros d'articles\"\"\"\n",
    "    \n",
    "    # Chercher tous les articles X et regarder ensuite si le match contient immédiatement avant, et immédiatement après un <p>\n",
    "    # Dans la regex ci-dessous, les (.{5})? contiennent les 5 caractères immédiatement avant et immédiatement après, s'il y en a u moins 5 avant et après\n",
    "    regex_article_semantique = r\"(?P<avant>.{5})?[\\s]*(?P<bouvrant><b>)?[\\s]*A(?:rticle|RTICLE)[\\s]*(?P<numero>[\\d]+)(?:er|°)?[\\s]*[:]?[\\s]*(?P<bfermant><\\/b>)?[\\s]*(?P<apres>.{5})?\"\n",
    "    \n",
    "    # @TOD0 prévoir l'absence de : ou une balise <b> fermant avant le :\n",
    "    \n",
    "    def re_replacement_numero_article(match: re.Match) -> str:\n",
    "        \"\"\"Fonction à utiliser comme paramètre replacement de la fonction re.sub pour nettoyer les numéros d'articles\"\"\"\n",
    "        \n",
    "        bouvrant = \"<b>\"\n",
    "        bfermant = \"</b>\"\n",
    "        \n",
    "        dictionnaire = match.groupdict()\n",
    "        # Contains {'first_name': 'Malcolm', 'last_name': 'Reynolds'}\n",
    "        new_text = \"\"\n",
    "        if verbose: print(\"Nouveau match : \",str(dictionnaire))\n",
    "        if dictionnaire[\"avant\"] is not None:\n",
    "            # Voir si contient <p>\n",
    "            new_text += dictionnaire[\"avant\"]\n",
    "            if \"<p>\" in dictionnaire[\"avant\"]:\n",
    "                if verbose: print(\"Précédé d'un début de paragraphe: \", dictionnaire[\"avant\"])\n",
    "            else:\n",
    "                if verbose: print(\"Non précédé d'un début de paragraphe: \", dictionnaire[\"avant\"])\n",
    "                if dictionnaire[\"bouvrant\"] is None and dictionnaire[\"bfermant\"] is not None: new_text += bfermant\n",
    "                new_text += \"</p><p>\"\n",
    "\n",
    "        # Traitement des balises bold b\n",
    "        if dictionnaire[\"bouvrant\"] is not None and dictionnaire[\"bfermant\"] is not None:\n",
    "            if verbose: print(\"On avait du bold ouvrant et fermant, on ne fait rien\")\n",
    "        if dictionnaire[\"bouvrant\"] is not None and dictionnaire[\"bfermant\"] is None:\n",
    "            if verbose: print(\"On avait du bold ouvrant mais PAS de fermant, on ne doit pas ajouter le b fermant\")\n",
    "            bfermant = \"\"\n",
    "\n",
    "        if dictionnaire[\"numero\"] is not None: # le contraire ne devrait jamais arriver\n",
    "            new_text += bouvrant + \"Article \" + dictionnaire[\"numero\"] + \"&nbsp;:\" + bfermant + \" \"\n",
    "        else:\n",
    "            print(\"Erreur, la regex ne devrait pas prendre des articles sans numéro\")\n",
    "        if dictionnaire[\"apres\"] is not None:\n",
    "            # Voir si contient </p>? Finalement, non car peut contenir titre d'article\n",
    "            # On se contente de ne pas supprimer la partie après\n",
    "            new_text += dictionnaire[\"apres\"]\n",
    "\n",
    "        if verbose: print(\"New text : \", new_text)\n",
    "\n",
    "        return new_text\n",
    "    \n",
    "    text = re.sub(regex_article_semantique, re_replacement_numero_article, text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_html_arrete(text: str, verbose: bool = False) -> str:\n",
    "    \"\"\"Fonction permettant de nettoyer le code html d'un bloc via des fonctions génériques\"\"\"\n",
    "    \n",
    "    #print(\"---------------------\")\n",
    "    #print(\"-------DEBUT---------\")\n",
    "    #print(text)\n",
    "    \n",
    "    # Nettoyer les balises inutiles; exemples </b>[\\s]+<b> OU <b>[\\s]+</b>\n",
    "    # 1ère: bold interrompu\n",
    "    regex_bold_interrompu = r\"<\\/b>\\s*<b>\" # à remplacer par une espace\n",
    "    text = re.sub(regex_bold_interrompu, \" \", text)\n",
    "    # 2ème: bold vide\n",
    "    regex_bold_vide = r\"<b>\\s*<\\/b>\" # à remplacer par une espace\n",
    "    text = re.sub(regex_bold_vide, \" \", text)\n",
    "    # 2ème: espace entre balises p (3 étapes)\n",
    "    regex_balises_p_separees = r\"</p>\\s+<p>\"\n",
    "    text = re.sub(regex_balises_p_separees, \"</p><p>\", text)\n",
    "    regex_balises_p_separees = r\"<p>\\s+<\"\n",
    "    text = re.sub(regex_balises_p_separees, \"<p><\", text)\n",
    "    regex_balises_p_separees = r\">\\s+<\\/p>\"\n",
    "    text = re.sub(regex_balises_p_separees, \"></p>\", text)\n",
    "    \n",
    "    # Ajouter des fins de paragraphe avant et après les numéros d'articles:  <b>ARTICLE 1 : </b>\n",
    "    text = replacement_numero_article(text, verbose)\n",
    "    \n",
    "    # @TODO Ajouter le cas où un <b> \"dépasse\" avant ou après le numéro d'article. Voir arrêté 2022-296 et 2022-363\n",
    "    # RÊTÉ </b></p><p> <b>ARTICLE 1 : </b> <b> </b> <b>Monsieur Patrick KARAM</b> ,\n",
    "    # erezerfs. </p><p>   <b>Article 4        :      dispositifs in\n",
    "    \n",
    "    # Voir pour tests: https://regex101.com/r/sLFDgf/1\n",
    "    \n",
    "    # @TODO nettoyer les en tetes\n",
    "    # <p> <b>Conseil régional </b> <b> </b> 2, rue Simone Veil – 93400 Saint-Ouen-sur-Seine  Tel: 01 53 85 53 85 –  www.iledefrance.fr            RegionIleDeFrance            @iledefrance     </p>\n",
    "    # <p> <b>Région Île-de-France </b> <b> </b></p><p> 2, rue Simone Veil – 93400 Saint-Ouen  Tél. : 01 53 85 53 85 –  www.iledefrance.fr  </p>\n",
    "    \n",
    "    # 9ème: espaces multiples\n",
    "    regex_espaces_multiples = r\"\\s{2,}\" # à remplacer par une espace\n",
    "    text = re.sub(regex_espaces_multiples, \" \", text)\n",
    "    # 9ème: blocs vides (return \"\")\n",
    "    regex_bloc_vide = r\"\\s*<p>\\s*<\\/p>\\s*\"\n",
    "    text = re.sub(regex_bloc_vide, \"\", text)\n",
    "    \n",
    "    regex_balises_p_separees = r\"<p>\\s+<\"\n",
    "    text = re.sub(regex_balises_p_separees, \"<p><\", text)\n",
    "    regex_balises_p_separees = r\">\\s+<\\/p>\"\n",
    "    text = re.sub(regex_balises_p_separees, \"></p>\", text)\n",
    "    \n",
    "    # <p><b>Conseil régional</b></p>\n",
    "    regex_blocs_a_supprimer = r\"<p><b>Conseil régional<\\/b><\\/p>\"\n",
    "    text = re.sub(regex_blocs_a_supprimer, \"\", text, flags=re.IGNORECASE)\n",
    "    # <p> 2, rue Simone Veil – 93400 Saint-Ouen-sur-Seine Tél : 01 53 85 53 85 – www.iledefrance.fr</p>\n",
    "    regex_blocs_a_supprimer = r\"<p>[\\s — -,:\\.]*2[\\s — -,:\\.]*rue Simone Veil[\\s — -,:\\.]*93400[\\s — -,:\\.]*Saint-Ouen(-sur-Seine)?[\\s — -,:\\.]*(Tél|Tel|Téléphone)?[\\s — -,:\\.]*((\\d\\s){3}){5}[\\s — -,:\\.]*www.iledefrance.fr[\\s — -,:\\.]*(RegionIleDeFrance)?[\\s — -,:\\.]*(@iledefrance)?[\\s -,:\\.]*<\\/p>\"\n",
    "    text = re.sub(regex_blocs_a_supprimer, \"\", text, flags=re.IGNORECASE)\n",
    "    # <p> RegionIleDeFrance @iledefrance</p>\n",
    "    regex_blocs_a_supprimer = r\"<p>[\\s -,:\\.]*RegionIleDeFrance[\\s -,:\\.]*@iledefrance[\\s -,:\\.]*<\\/p>\"\n",
    "    text = re.sub(regex_blocs_a_supprimer, \"\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # <p>Conseil régional</p>.{0,5}<p>.{0,5}2.{0,5}rue Simone Veil.{0,5}93400.{0,5}SAINT-OUEN.{0,5}T(?:é|e)l.{0,5}01.?53.?85.?53.?85.{0,5}Fax.{0,5}01.?53.?85.?53.?89.?www.?iledefrance.?fr.{0,5}</p>.{0,5}<p>.{0,50}</p>\n",
    "    regex_blocs_a_supprimer = r\"<p>Conseil régional(?:</p>.{0,5}<p>|.{0,10}).{0,5}2.{0,5}rue Simone Veil.{0,10}93400.{0,10}SAINT-OUEN.{0,10}T(?:é|e)l.{0,10}01.{0,2}53.{0,2}85.{0,2}53.{0,2}85.{0,10}(?:Fax.{0,10}01.{0,2}53.{0,2}85.{0,2}53.{0,2}89)?.?www.?iledefrance.?fr.{0,5}</p>(?:[^<>]){0,10}(?:<p>.{0,50}</p>)?\"\n",
    "    text = re.sub(regex_blocs_a_supprimer, \"\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # <p>.{0,10}Région Île-de-France.{0,10}</p>.{0,10}<p>2.{0,5}rue Simone Veil.{0,10}93400.{0,5}Saint-Ouen.{0,10}T(?:é|e)l.{0,5}01.?53.?85.?53.?85.{0,10}www.iledefrance.fr</p>.{0,10}<p>R.{0,10}leDeFrance.{0,10}@.{0,10}de.?rance</p>\n",
    "    regex_blocs_a_supprimer = r\"<p>.{0,10}Région Île-de-France.{0,10}</p>(?:[^<>]){0,10}<p>2.{0,5}rue Simone Veil.{0,10}93400.{0,5}Saint-Ouen.{0,10}T(?:é|e)l.{0,5}01.?53.?85.?53.?85.{0,10}www.iledefrance.fr</p>(?:[^<>]){0,10}<p>R.{0,10}leDeFrance.{0,10}@.{0,10}de.?rance</p>\"\n",
    "    text = re.sub(regex_blocs_a_supprimer, \"\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    regex_signature_a_nettoyer = r\"<p>.{0,13}?</p><p>Valérie P(?:É|E)CRESSE</p>\"\n",
    "    text = re.sub(regex_signature_a_nettoyer, \"<p>Valérie PÉCRESSE</p>\", text)\n",
    "    \n",
    "    # article 1°[\\S]{0,3}\n",
    "    regex_article_premier = r\"article 1°[\\S]{0,3}\"\n",
    "    text = re.sub(regex_signature_a_nettoyer, \"article 1er\", text)\n",
    "    \n",
    "    # re.findall(regex_article_semantique, block_text)\n",
    "    # re.match(regex_article_semantique, block_text)\n",
    "    # Match.expand(template)\n",
    "    # Return the string obtained by doing backslash substitution on the template string template,\n",
    "    # as done by the sub() method. Escapes such as \\n are converted to the appropriate characters,\n",
    "    # and numeric backreferences (\\1, \\2) and named backreferences (\\g<1>, \\g<name>) are replaced\n",
    "    # by the contents of the corresponding group.\n",
    "    # re.sub(pattern, replacement, string) replaces all occurrences of pattern by replacement in string\n",
    "    # C'est un negative lookahead pour vérifier si la string est suivie par... (?!...) \n",
    "    # et un negative lookbehind pour vérifier si la string est précédée par ... (?<!...)\n",
    "    \n",
    "    #print(\"--------FIN----------\")\n",
    "    #print(text)\n",
    "    #print(\"---------------------\")\n",
    "    #print(\"---------------------\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def prepare_identifiant_from_prepare(identifiant: str) -> str:\n",
    "    \"\"\"Nettoie l'identifiant à partir d'un identifiant préparé, c'est-à-dire extrait par une regex large spectre\"\"\"\n",
    "    regex_identifiant_prepare = r\"(?P<annee>[\\d]{4}|15|16|17|18|19|20)[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}(?P<numero>[\\d\\s]{2,4})(?:[-‐‑-−‒-‒––⁃─−―–−‒\\s]{1,3}(?P<supplement>[\\d]{0,1}))?\"\n",
    "    identifiant_prepare = re.search(regex_identifiant_prepare, identifiant, re.IGNORECASE)\n",
    "    if identifiant_prepare:\n",
    "        annee = identifiant_prepare.group('annee')\n",
    "        numero = identifiant_prepare.group('numero').replace(\" \",\"\")\n",
    "        if(len(numero) == 2):\n",
    "            numero = \"0\" + numero\n",
    "        supplement = identifiant_prepare.group('supplement')\n",
    "        identifiant = \"AR\" + annee + \"-\" + numero\n",
    "        if supplement is not None and len(supplement) > 0:\n",
    "            identifiant += \"-\" + str(supplement)\n",
    "    else:\n",
    "        print(\"Identifiant non reconnu par regex : \", identifiant)\n",
    "    return identifiant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2d1f86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_html(dictionary_elements: dict, verbose: bool = False) -> str:\n",
    "    block_text = \"\"\n",
    "    for block in dictionary_elements['blocks']:\n",
    "        #print(block)\n",
    "        \n",
    "        # TODO Pour les visas, préférer les ul / li aux paragraphes classiques\n",
    "        \n",
    "        block_text += \"<p>\"\n",
    "        for line in block['lines']:\n",
    "            line_text = \"\"\n",
    "            for span in line['spans']:\n",
    "                #print(span)\n",
    "                if \"Bold\" in span['font'] or \"bold\" in span['font']:\n",
    "                    if \"Italic\" in span['font'] or \"italic\" in span['font']:\n",
    "                        texte_a_inclure = \"<b><i>\" + span['text'] + \"</i></b>\"\n",
    "                    else:\n",
    "                        texte_a_inclure = \"<b>\" + span['text'] + \"</b>\"\n",
    "                else :\n",
    "                    texte_a_inclure = span['text']\n",
    "                line_text += \" \" + texte_a_inclure\n",
    "                #print(span)\n",
    "            block_text += line_text\n",
    "            #line_text += \" STOP \"\n",
    "            #print(line_text)\n",
    "        #block_text = re.sub(' +', ' ', block_text.strip())\n",
    "        block_text += \"</p>\"\n",
    "        \n",
    "    # On nettoie le code avec une fonction personnalisée\n",
    "    block_text = clean_html_arrete(block_text, verbose)\n",
    "        \n",
    "    return block_text\n",
    "\n",
    "def nettoie_date_aaaa_mois_jj(date):\n",
    "    regex_date_francais = r\"(?P<annee>[\\d]{4})-(?P<mois>[jfmasondJFMASOND][\\w]{2,9})-(?P<jour>[\\d]{1,2})\"\n",
    "    match_date_decision = re.search(regex_date_francais, date, re.IGNORECASE)\n",
    "    if match_date_decision:\n",
    "        mois = match_date_decision.group('mois')\n",
    "        if (re.search(r\"jan\", mois, re.IGNORECASE)):\n",
    "            mois = \"01\"\n",
    "        elif (re.search(r\"vrier\", mois, re.IGNORECASE)):\n",
    "            mois = \"02\"\n",
    "        elif (re.search(r\"mars\", mois, re.IGNORECASE)):\n",
    "            mois = \"03\"\n",
    "        elif (re.search(r\"avril\", mois, re.IGNORECASE)):\n",
    "            mois = \"04\"\n",
    "        elif (re.search(r\"juin\", mois, re.IGNORECASE)):\n",
    "            mois = \"06\"\n",
    "        elif (re.search(r\"juil\", mois, re.IGNORECASE)):\n",
    "            mois = \"07\"\n",
    "        elif (re.search(r\"ao\", mois, re.IGNORECASE)):\n",
    "            mois = \"08\"\n",
    "        elif (re.search(r\"sep\", mois, re.IGNORECASE)):\n",
    "            mois = \"09\"\n",
    "        elif (re.search(r\"oct\", mois, re.IGNORECASE)):\n",
    "            mois = \"10\"\n",
    "        elif (re.search(r\"nov\", mois, re.IGNORECASE)):\n",
    "            mois = \"11\"\n",
    "        elif (re.search(r\"cemb\", mois, re.IGNORECASE)):\n",
    "            mois = \"12\"\n",
    "        elif (re.search(r\"mai\", mois, re.IGNORECASE)):\n",
    "            mois = \"05\"\n",
    "        else:\n",
    "            mois = \"08\"\n",
    "        jour = \"0\" + match_date_decision.group('jour')\n",
    "        jour = jour[-2:]\n",
    "        return match_date_decision.group('annee') + \"-\" + mois + \"-\" + jour\n",
    "    else:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4f766c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_arrete(dictionary_elements: dict, verbose: bool = False):\n",
    "    \n",
    "    limite_inf = 0\n",
    "    limite_sup = 950\n",
    "    corps_visa_arrete = \"\"\n",
    "    controle_legalite = \"\"\n",
    "    date_decision = \"\"\n",
    "    date_decision_debut = False\n",
    "    fin = False\n",
    "    \n",
    "    dictionnaire_expurge = {'blocks': []}\n",
    "    \n",
    "    for block in dictionary_elements['blocks']:\n",
    "\n",
    "        x0, y0, x1, y1 = block['bbox']\n",
    "        \n",
    "        texte = \"\"\n",
    "        \n",
    "        for line in block['lines']:\n",
    "            for span in line['spans']:\n",
    "                texte += \" \" + span['text']\n",
    "        \n",
    "        if (y0 > limite_inf and y1 < limite_sup):\n",
    "            dictionnaire_expurge['blocks'].append(block)\n",
    "        else:\n",
    "            print(\"SUPPRIME en-tête / pied de page : \" + texte)\n",
    "            \n",
    "        if (\"Envoyé en préfecture le\" in texte):\n",
    "            # On enregistre le contrôle de légalité\n",
    "            controle_legalite = texte\n",
    "            #fin = True\n",
    "            break\n",
    "                \n",
    "        if (\"Fait à\" in texte):\n",
    "            date_decision_debut = True\n",
    "        \n",
    "        if (date_decision_debut and date_decision == \"\"):\n",
    "            regex_date_francais = r\"(?P<jour>[\\d]{1,2})[\\s-]{1,5}(?P<mois>[JFMASONDjfmasond][\\w]{2,9})[\\s-]{1,5}(?P<annee>[\\d]{4})\"\n",
    "            match_date_decision = re.search(regex_date_francais, texte, re.IGNORECASE)\n",
    "            if match_date_decision:\n",
    "                date_decision = nettoie_date_aaaa_mois_jj(match_date_decision.group('annee') + \"-\" + match_date_decision.group('mois') + \"-\" + match_date_decision.group('jour'))\n",
    "        \n",
    "        #Fait à Saint-Ouen-sur-Seine en 1 exemplaire\n",
    "        #Le\n",
    "        #La présidente du conseil régional\n",
    "        #Valérie PECRESSE\n",
    "        #Par délégation,\n",
    "        #L’adjointe à la cheffe du service des relations\n",
    "        #avec les organismes\n",
    "        #Laurence LARIDANT\n",
    "        #09 Mai 2022\n",
    "            \n",
    "        \"\"\"\n",
    "        CONTROLE SUR LES SUPPRESSIONS LIEES AUX MARGES\n",
    "        if (y0 > limite_inf and y1 < limite_sup):\n",
    "            print(\"y0 = \" + str(y0) + \" et y1 = \" + str(y1) + \" :\" + texte)\n",
    "        else:\n",
    "            print(\" \")\n",
    "            print(\"Supprimé: \" + texte)\n",
    "            print(\" \")\n",
    "        \"\"\"\n",
    "    corps_visa_arrete = dict_to_html(dictionnaire_expurge, verbose)\n",
    "\n",
    "    return (corps_visa_arrete, controle_legalite, date_decision, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cae6085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_titre_date_arrete(dictionary_elements: dict, page_annots = None, verbose: bool = False):\n",
    "    ide = \"\"\n",
    "    titre = \"\"\n",
    "    identifiant_complet = False\n",
    "    identifiant_tronque_a_completer = \"\"\n",
    "    yinitial = 0\n",
    "    titre_is_next = 0\n",
    "    iteration_titre = 0\n",
    "    date_decision_is_next = 0\n",
    "    iteration_date = 0\n",
    "    date_decision = \"\"\n",
    "    \n",
    "    font = \"\"\n",
    "    size = \"\"\n",
    "    font_titre = \"\"\n",
    "    size_titre = \"\"\n",
    "    \n",
    "    regex_identifiant_arrete_complet = r\"[arêeténARETÊÉN° ]{6,15}(?:[ MODIFCATRmodifcatnN°\\s]{10,17})?(?P<identifiant>[\\d]{4}\\s?-\\s?[\\d]{2,3}(?:-[\\d]{0,1})?)(?:[\\s][dDuU]{2}[\\s](?P<jour>[\\d]{1,2})[\\s-]{1,2}(?P<mois>[jfmasondJFMASOND][\\w]{2,9})[\\s-]{1,2}(?P<annee>[\\d]{4}))\" # Ex: 2022-342-1\n",
    "    regex_identifiant_arrete_numsansdate = r\"[arêeténARETÊÉN-°\\s]{6,15}(?:[ MODIFCATRmodifcatnN°\\s]{10,17})?(?P<identifiant>[\\d]{4}\\s*-\\s*[\\d]{2,3}(?:\\s?-\\s?[\\d]{0,1})?)\" # Juste 2022-123\n",
    "    regex_identifiant_arrete_tronque = r\"[arêeténARETÊÉN-°\\s]{6,15}(?:[ MODIFCATRmodifcatnN°\\s]{10,17})?([\\d]{4}\\s?-)\" # Juste 2022-\n",
    "    regex_id_controle_legalite = r\"(?:ID :)[\\s]{0,3}[\\d]{2,3}-[\\d]{5,20}-[\\d]{5,20}-([\\d]{4})_([\\d]{3})[_]?([\\d]{1})?-AR\"\n",
    "    regex_trois_chiffres = r\"^[\\s]{0,5}([\\d]{3})[\\s]{0,5}$\"\n",
    "    regex_date_decision_seule = r\"^\\s*[DUdu\\s]{2,4}(?P<jour>[\\d]{1,2})[\\s-]{1,2}(?P<mois>[jfmasondJFMASOND][\\w]{2,9})[\\s-]{1,2}(?P<annee>[\\d]{4})\"\n",
    "    regex_date_decision_annot = r\"[DUdu\\s]{2,4}(?P<jour>[\\d]{1,2})[\\s-]{1,2}(?P<mois>[jfmasondJFMASOND][\\w]{2,9})[\\s-]{1,2}(?P<annee>[\\d]{4})\"\n",
    "    regex_titre = r\"(?P<titre>(?:portant|de cession|apportant|de désignation|de design|de délég|de nominat|délégu|d'agrément|régissant|emportant|autoris|fixant|relatif|creant|concernant|créant|modifi).{10,150})\"\n",
    "    \n",
    "    for annot in page_annots:\n",
    "        if (\"FreeText\" in annot.type and annot.info is not None):\n",
    "            cherche_identifiant_sansdate = re.search(regex_identifiant_arrete_numsansdate, annot.info['content'])\n",
    "            if (cherche_identifiant_sansdate is not None):\n",
    "                ide = \"AR\" + cherche_identifiant_sansdate.group('identifiant').replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                if (verbose): print(\"IDE récupéré dans une annotation\", ide)\n",
    "            cherche_date_decision_annot = re.search(regex_date_decision_annot, annot.info['content'])\n",
    "            if (cherche_date_decision_annot is not None):\n",
    "                date_decision = convertir_date_ods(cherche_date_decision_annot.group('jour') + \" \" + cherche_date_decision_annot.group('mois') + \" \" + cherche_date_decision_annot.group('annee'))\n",
    "                if (verbose): print(\"DATE DECISION récupérée dans une annotation\", date_decision)\n",
    "            # print(annot.info)\n",
    "        elif (\"Stamp\" in annot.type):\n",
    "            if (verbose): print(annot.get_text())\n",
    "        else:\n",
    "            if (verbose): print(\"Autre type : \", annot.type)\n",
    "    \n",
    "    for block in dictionary_elements['blocks']:\n",
    "        \n",
    "        # block_text = \"\"\n",
    "        #print(\"BLOCK\")\n",
    "        #print(block)\n",
    "        \n",
    "        for line in block['lines']:\n",
    "            line_text = ''\n",
    "            for span in line['spans']:\n",
    "                line_text += \" \" + span['text']\n",
    "                font = str(span['font'])\n",
    "                size = str(span['size'])[:5]\n",
    "            \n",
    "            # block_text += \" \" + line_text.strip().rstrip('\\r\\n')\n",
    "            \n",
    "            cherche_identifiant_complet = re.findall(regex_identifiant_arrete_complet, line_text)\n",
    "            cherche_identifiant_numsansdate = re.findall(regex_identifiant_arrete_numsansdate, line_text)\n",
    "            cherche_identifiant_tronque = re.findall(regex_identifiant_arrete_tronque, line_text)\n",
    "            cherche_id_controle_legalite = re.findall(regex_id_controle_legalite, line_text)\n",
    "            cherche_trois_chiffres = re.findall(regex_trois_chiffres, line_text)\n",
    "            \n",
    "            cherche_titre = re.search(regex_titre, line_text, re.IGNORECASE)\n",
    "            \n",
    "            if (titre_is_next == 2):\n",
    "                # On compare la taille et la font avec celle du titre\n",
    "                if (font == font_titre and size == size_titre):\n",
    "                    # On ajoute la ligne au titre\n",
    "                    titre = titre + \" \" + line_text.strip()\n",
    "                titre_is_next = 3\n",
    "            \n",
    "            if (iteration_titre < 3 and titre_is_next == 1 and cherche_titre is not None and len(cherche_titre.group('titre')) > 5 and titre == \"\"):\n",
    "                # On stocke la font + la taille de police pour repérer le prochain bloc\n",
    "                font_titre = font\n",
    "                size_titre = size\n",
    "                titre = cherche_titre.group('titre').strip().rstrip('\\r\\n')\n",
    "                # print(\"TITRE ARRIVE ICI : \" + line_text + \" // \" + cherche_titre.group('titre'))\n",
    "                titre_is_next = 2\n",
    "            else:\n",
    "                iteration_titre += 1\n",
    "            \n",
    "            if (date_decision_is_next == 1 and line_text.strip().rstrip('\\r\\n') != \"\"):\n",
    "                if (verbose): print(\" --- Date de décision prochaine\")\n",
    "                cherche_date_decision_seule = re.findall(regex_date_decision_seule, line_text)\n",
    "                #print(\" ICI \")\n",
    "                #print(cherche_date_decision_seule)\n",
    "                # print(\" ICI \")\n",
    "                # print(cherche_titre)\n",
    "                if (cherche_titre is not None and len(cherche_titre.group('titre')) and titre == \"\"):\n",
    "                    font_titre = font\n",
    "                    size_titre = size\n",
    "                    titre = cherche_titre.group('titre')\n",
    "                    # print(\" TITRE FIXE ICI : \" + titre)\n",
    "                    titre_is_next = 2\n",
    "                if (len(cherche_date_decision_seule) and len(cherche_date_decision_seule[0]) > 2):\n",
    "                    #print(\" - - - \"+ str(cherche_date_decision_seule))\n",
    "                    date_decision = convertir_date_ods(cherche_date_decision_seule[0][0] + \" \" + cherche_date_decision_seule[0][1] + \" \" + cherche_date_decision_seule[0][2])\n",
    "                    date_decision_is_next = 2\n",
    "                    if (titre_is_next < 2):\n",
    "                        titre_is_next = 1\n",
    "            \n",
    "            if (len(cherche_identifiant_complet) and identifiant_complet == False and identifiant_tronque_a_completer == \"\" and ide == \"\"):\n",
    "                if (verbose): print(\" --- IDE COMPLET\")\n",
    "                if (verbose): print(cherche_identifiant_complet)\n",
    "                # [('2022-209', '7', 'juillet', '2022')]\n",
    "                ide = \"AR\" + cherche_identifiant_complet[0][0].replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                if (len(cherche_identifiant_complet[0]) > 2):\n",
    "                    if (verbose): print(\"DATE TROUVEE AU DEBUT\")\n",
    "                    date_decision = convertir_date_ods(cherche_identifiant_complet[0][1] + \" \" + cherche_identifiant_complet[0][2] + \" \" + cherche_identifiant_complet[0][3]) #TODO\n",
    "                identifiant_complet = True\n",
    "                titre_is_next = 1\n",
    "            elif (identifiant_complet == False and ide == \"\"):\n",
    "                # Prendre en compte les numéros d'arrêtés qui ont été ajoutés à posteriori, avant envoi au contrôle de légalité\n",
    "                # print(\"pas trouvé // \" + line_text)\n",
    "                if (len(cherche_identifiant_numsansdate) and identifiant_tronque_a_completer == \"\"):\n",
    "                    # print(\" --- On a trouvé le numéro ide sans date\")\n",
    "                    # On a trouvé le numéro ide sans date\n",
    "                    date_decision_is_next = 1\n",
    "                    ide = \"AR\" + cherche_identifiant_numsansdate[0]\n",
    "                elif (identifiant_tronque_a_completer != \"\"):\n",
    "                    # On a trouvé et enregistré la partie tronquée de l'identifiant tronqué\n",
    "                    # print(\"ID TRONQUE DEJA COMPLETE // \" + identifiant_tronque_a_completer)\n",
    "                    # print(\"LINE \" + line_text)\n",
    "                    if(len(cherche_trois_chiffres)): # Trouve complément\n",
    "                        # print(\"TROIS CHIFFRES TROUVES //\" + line_text)\n",
    "                        a, yfinal, c, d = line[\"bbox\"]\n",
    "                        # print(\"Ecart des y0 : init \" + str(yinitial) + \" - yfin \" + str(yfinal) + \" = \" + str(yinitial-yfinal))\n",
    "                        if (abs(yinitial-yfinal) > 10):\n",
    "                            print(\"Alerte écart important : \" + str(yinitial-yfinal))\n",
    "                        ide = \"AR\" + identifiant_tronque_a_completer + cherche_trois_chiffres[0]\n",
    "                        print(\"Identifiant complet \" + ide)\n",
    "                if (len(cherche_identifiant_tronque) and identifiant_tronque_a_completer == \"\" and ide == \"\"):\n",
    "                    if (verbose): print(\"ID TRONQUE TROUVE // \" + line_text)\n",
    "                    #On a trouvé un identifiant tronqué à compléter\n",
    "                    identifiant_tronque_a_completer = cherche_identifiant_tronque[0].replace(\" \", \"\").rstrip('\\r\\n')\n",
    "                    #On enregistre la hauteur y0 de la ligne\n",
    "                    a, yinitial, c, d = line[\"bbox\"]\n",
    "                    titre_is_next = 1\n",
    "        \n",
    "        # print(\"BLOCK : \" + block_text.strip().rstrip('\\r\\n'))      \n",
    "    \n",
    "    ide = prepare_identifiant_from_prepare(ide)\n",
    "    #if (titre_is_next >= 2):\n",
    "    #    titre = \"Arrêté n°\" + numero_from_identifiant(ide) + \" \" + titre\n",
    "    #else:\n",
    "    #    titre = \"Arrêté n°\" + numero_from_identifiant(ide)\n",
    "    #print (\"TITRE : \" + titre)\n",
    "        \n",
    "    return (ide, titre.strip(), date_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cc91e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_controle(controle_legalite: str) -> str:\n",
    "    # regex_controle = r\"Envoyé en préfecture le[\\s]{0,3}([\\d]{2})/([\\d]{2})/([\\d]{4})\" #13/05/2022\n",
    "    regex_controle = r\"le\\s{0,3}([\\d]{2})\\s*/\\s*([\\d]{2})\\s*/\\s*([\\d]{4})\" #13/05/2022\n",
    "    date = re.findall(regex_controle, controle_legalite)\n",
    "    if (len(date)):\n",
    "        annee = date[0][2]\n",
    "        mois = date[0][1]\n",
    "        jour = date[0][0]\n",
    "        return annee + \"-\" + mois + \"-\" + jour\n",
    "    else:\n",
    "        return \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b0921",
   "metadata": {},
   "source": [
    "# Traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0b70af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def traite_fichier_arrete(nom_fichier: str, verbose: bool = False) -> dict:\n",
    "    \"\"\"Analyse un fichier\"\"\"\n",
    "    \n",
    "    # Initialiser les valeurs\n",
    "    identifiant = \"\"\n",
    "    numero = \"\"\n",
    "    titre = \"\"\n",
    "    controle_legalite = \"\"\n",
    "    date_decision = \"\"\n",
    "    corps_visa_arrete = \"\"\n",
    "    url1 = \"\"\n",
    "    \n",
    "    pdf = fitz.open(nom_fichier)\n",
    "    \n",
    "    #Est-ce un rapport ou une délibération ?\n",
    "    page_de_garde = pdf.load_page(0).get_text()\n",
    "    \n",
    "    #Extraire contrôle de légalité\n",
    "    controle_legalite = extract_date_controle(page_de_garde)\n",
    "    \n",
    "    # print(page_de_garde)\n",
    "    detect_arrete = re.findall(r\"[arêeténARETÊÉN° ]{6,15}(?:[ MODIFCATmodifcatnN°\\s]{10,17})?([\\d]{4}-[\\d]{2,3}(?:-[\\d]{0,1})?)\", page_de_garde)\n",
    "    if (len(detect_arrete) and len(page_de_garde) > 200):\n",
    "        #if (\"ARRETÉ N°\" in page_de_garde or \"ARRÊTÉ N°\" in page_de_garde):\n",
    "        type_document = \"arretetext\"\n",
    "    elif ((\"Envoyé en préfecture le\" in page_de_garde) or (\"Reçu en préfecture le\" in page_de_garde)):\n",
    "        type_document = \"arreteocr\"\n",
    "    else:\n",
    "        type_document = \"arreteocr\"\n",
    "    \n",
    "    # Contrôles de cohérence et message\n",
    "    messages = []\n",
    "    if ((type_document == \"arretetext\" or type_document == \"arreteocr\") and not \"AR\" in nom_fichier):\n",
    "        messages.append(\"AR non présent dans le nom de fichier\")\n",
    "    if (\"RAP\" in nom_fichier or \"DEL\" in nom_fichier):\n",
    "        messages.append(\"RAP ou DEL présent dans le nom de fichier\")\n",
    "    if (type_document == \"autre\"):\n",
    "        messages.append(\"Fichier non reconnu: \" + str(pdf))\n",
    "    \n",
    "    #\n",
    "    # Analyse des arrêtes sans OCR\n",
    "    #\n",
    "    if (type_document == \"arretetext\"):\n",
    "        \n",
    "        print(\" =====TEXT===== \")\n",
    "        print(\"DEBUT DOC \" + nom_fichier)\n",
    "        \n",
    "        # Récupérer identifiant, titre (et éventuellement date si présente)\n",
    "        page = pdf.load_page(0)\n",
    "        tp = page.get_textpage()\n",
    "        dictionary_elements = tp.extractDICT()\n",
    "        for annot in page.annots():\n",
    "            if (\"FreeText\" in annot.type):\n",
    "                if (verbose): print(\"Annotation de type FreeText : \", annot.info)\n",
    "            elif (\"Stamp\" in annot.type):\n",
    "                if (verbose): print(\"Annotation de type Stamp : \", annot.get_text())\n",
    "            else:\n",
    "                if (verbose): print(\"Autre type d'annotation : \", annot.type)\n",
    "        identifiant, titre, date_decision_part_debut = extract_id_titre_date_arrete(dictionary_elements, page.annots(), verbose)\n",
    "        \n",
    "        identifiant_compare = prepare_identifiant_from_prepare(nom_fichier)\n",
    "        if (identifiant != identifiant_compare):\n",
    "            identifiant = identifiant_compare\n",
    "            print(\"Identifiant non conforme au nom de fichier : \", identifiant, \". L'identifiant du nom de fichier a été récupéré : \", identifiant_compare)\n",
    "\n",
    "        # OK print(identifiant)\n",
    "        # OK print(titre)\n",
    "        \n",
    "        # print(\"DATE DECISION RECUE PART DEBUT : \" + date_decision_part_debut)\n",
    "        \n",
    "        numero = numero_from_identifiant(identifiant)\n",
    "        url1 = \"https://www.iledefrance.fr/actes/arretes/\" + nom_fichier\n",
    "        \n",
    "        # Récupérer corps_visa_delib\n",
    "        corps_visa_arrete = \"\"\n",
    "        \n",
    "        for i in range(0, pdf.page_count):\n",
    "            page = pdf.load_page(i)\n",
    "            tp = page.get_textpage()\n",
    "            dictionary_elements = tp.extractDICT()\n",
    "            corps_visa_arrete_part, controle_legalite_part, date_decision, fin = extract_all_arrete(dictionary_elements, verbose)\n",
    "            corps_visa_arrete += corps_visa_arrete_part\n",
    "            controle_legalite += controle_legalite_part\n",
    "            # print(\"DATE DECISION RECUE : \" + date_decision)\n",
    "            if (fin):\n",
    "                break\n",
    "            \n",
    "        if (controle_legalite != \"\"):\n",
    "            print(\"Controle \" + controle_legalite)\n",
    "            controle_legalite = extract_date_controle(controle_legalite)\n",
    "        \n",
    "        if (date_decision == \"\"):\n",
    "            print(\"Date_decision vide, on prend date_decision_part_debut : \" + date_decision_part_debut)\n",
    "            date_decision = date_decision_part_debut\n",
    "    \n",
    "    #\n",
    "    # Analyse des arrêtes avec OCR\n",
    "    #\n",
    "    if (type_document == \"arreteocr\"):\n",
    "        \n",
    "        print(\" =====OCR===== \")\n",
    "        print(\"DEBUT DOC \" + nom_fichier)\n",
    "        \n",
    "        identifiant = nom_fichier\n",
    "        titre_part, text, paragraphes_html,identifiant,date_decision,date_controle = traitement_ocr(nom_fichier)\n",
    "        \n",
    "        if (titre_part != \"\"):\n",
    "            titre += \" \" + titre_part\n",
    "        titre = titre.replace(\"  \", \" \").strip()\n",
    "        # print(\"=======\",paragraphes_html)\n",
    "        for blocks in paragraphes_html:\n",
    "            for paragraphes in blocks:\n",
    "                #print(paragraphes_html)\n",
    "                corps_visa_arrete += paragraphes\n",
    "        \n",
    "        numero = numero_from_identifiant(identifiant)\n",
    "        url1 = \"https://www.iledefrance.fr/actes/arretes/\" + nom_fichier\n",
    "        \n",
    "        if (controle_legalite == \"\"):\n",
    "            controle_legalite = date_controle\n",
    "    \n",
    "    titre = (\"Arrêté n°\" + numero + \" \" + titre).strip()\n",
    "    \n",
    "    print(\"Identifiant final : \", identifiant)\n",
    "    print(\"Titre final : \", titre)\n",
    "    print(\"Date décision finale : \", date_decision)\n",
    "    \n",
    "    if (controle_legalite != \"\"):\n",
    "        date_affichage = controle_legalite\n",
    "    elif (date_decision != \"\"):\n",
    "        date_affichage = date_decision\n",
    "    else:\n",
    "        date_affichage = date_publication(\"ok\")\n",
    "    \n",
    "    dictionnaire = {\"coll_nom\": \"Région Île-de-France\",\n",
    "                    \"coll_siret\": \"23750007900312\",\n",
    "                    \"identifiant\": identifiant,\n",
    "                    \"numero\": numero,\n",
    "                    \"titre\": titre,\n",
    "                    \"type_acte\": \"AR\",\n",
    "                    \"type\": \"Arrêtés de la Présidente\",\n",
    "                    \"type_seance\": \"Présidente du conseil régional\",\n",
    "                    \"theme\": \"Institution\",\n",
    "                    \"date_controle\": controle_legalite,\n",
    "                    \"date_decision\": date_decision,\n",
    "                    \"date_publication\": date_publication(\"ok\"),\n",
    "                    \"date_affichage\": date_affichage,\n",
    "                    \"texte_arrete\": corps_visa_arrete,\n",
    "                    \"messages\": str(messages),\n",
    "                    \"nom_fichier\": nom_fichier,\n",
    "                    \"url1\": url1\n",
    "                   }\n",
    "    \n",
    "    return dictionnaire\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ecf8f",
   "metadata": {},
   "source": [
    "# Declenchement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ad640b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#chemin dans lequel se trouve les arretés: A modifier au besoin\n",
    "os.chdir(\"C:/Users/utilisateur/Documents/Python Scripts/PUBLICATIONS ACTES/Arretes\")\n",
    "fileDirOrigin = \"C:/Users/utilisateur/Documents/Python Scripts/PUBLICATIONS ACTES/Arretes\"\n",
    "fichier_a_inscrire = fileDirOrigin + '/extrait_arretes.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d151b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_fichier =  [_ for _ in os.listdir(fileDirOrigin) if _.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f76135",
   "metadata": {},
   "source": [
    "# Ajouter une annotation de type timestamp pour la date de publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8c29819e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in liste_fichier:\n",
    "    if (file != \"AR2023-034.pdf\"):\n",
    "        continue\n",
    "    print(\"  === \", file, \" ===  \")\n",
    "    pdf = fitz.open(file)\n",
    "    xref = None\n",
    "    for index in range(0, pdf.page_count):\n",
    "        print(\"Page numéro \", index+1, \" :\")\n",
    "        page = pdf.load_page(index)\n",
    "        for annot in page.annots():\n",
    "            print(\"Annotation \", annot.xref, \" : \")\n",
    "            if (\"FreeText\" in annot.type):\n",
    "                continue\n",
    "            elif (\"Stamp\" in annot.type and page.number == 0):\n",
    "                print(\"ICI \", annot.flags)\n",
    "                print(annot.info)\n",
    "                xref = annot.xref\n",
    "                # page.add_stamp_annot(rect, stamp=10)\n",
    "            else:\n",
    "                print(\"Autre type : \", annot.type)\n",
    "            print(\"---\")\n",
    "    if (xref is not None):\n",
    "        page = pdf.load_page(0)\n",
    "        annot = page.load_annot(xref)\n",
    "        #stamp_text = annot.get_text()\n",
    "        #regex_stamp_text = \"Publié le\"\n",
    "        #stamp_text = re.sub(regex_stamp_text, regex_stamp_text + \" \" + datetime.today().strftime('%d/%m/%Y'), stamp_text)\n",
    "        a,b,c,d = annot.rect\n",
    "        # Rect(395.32000732421875, 75.0, 585.3200073242188, 87.0)\n",
    "        #a = 395\n",
    "        #b = 75\n",
    "        #c = 585\n",
    "        #d = 87\n",
    "        rect = fitz.Rect(a,d+10,c,d+33)\n",
    "        if (page.rotation % 360 == 90):\n",
    "            rect = fitz.Rect(c+10,b,c+33,d)\n",
    "        elif (page.rotation % 360 == 180):\n",
    "            rect = fitz.Rect(a,b-33,c,b-10)\n",
    "        elif (page.rotation % 360 == 270):\n",
    "            rect = fitz.Rect(a-33,b,a-10,d)\n",
    "        \n",
    "        date_publication = datetime.today().strftime('%d/%m/%Y')\n",
    "        date_publication = datetime(2023, 1, 20, 0, 15, 57, 779703).strftime('%d/%m/%Y')\n",
    "        print(\"Rotation de la page : \", page.rotation)\n",
    "        #page.set_rotation(0)\n",
    "        annot = page.add_freetext_annot(rect, \"Publication des actes de la Région Île-de-France\\nPublié le \" + date_publication, fontsize=8, fontname='helv', border_color=(0, 0, 0.5), text_color=(0, 0, 0.5), fill_color=(0.95, 0.95, 1), rotate=page.rotation, align=fitz.TEXT_ALIGN_LEFT)\n",
    "        annot.set_border(width=1)\n",
    "        annot.set_flags(fitz.PDF_ANNOT_IS_LOCKED|fitz.PDF_ANNOT_IS_READ_ONLY|fitz.PDF_ANNOT_IS_LOCKED_CONTENTS)\n",
    "        annot.set_info(info={'name': 'Publication', 'title': 'Publication des actes administratifs', 'creationDate': str(datetime.today().strftime(\"D:%Y%m%d%H%M%S%z\")), 'modDate': str(datetime.today().strftime(\"D:%Y%m%d%H%M%S%z\")), 'subject': 'Date de publication'})\n",
    "        annot.update()\n",
    "        print(annot.info)\n",
    "        pdf.save(pdf.name, incremental=True, encryption=fitz.PDF_ENCRYPT_KEEP, permissions=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16263996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "394c26a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =====OCR===== \n",
      "DEBUT DOC AR2023-044.pdf\n",
      "Texte replace / :  Envoyé en préfecture le 06022023\n",
      "Texte replace / :  Reçu en préfecture le 06022023 ñ Publié le S L\n",
      "Texte replace / :  ID : 075-237500079-20230203-2023 044-AR\n",
      "Texte replace / :   \n",
      "Texte replace / :  # Région fleceFrance Conseil régional\n",
      "Texte replace / :  Ref : 123-CRIDF-00016\n",
      "Texte replace / :  ARRETE N°2023-044 DU 3 FEVRIER 2023\n",
      "Identifiant trouvé :  ARRETE N°2023-044 DU 3 FEVRIER 2023\n",
      "Match :  {'numero': '2023-044 ', 'jour': '3', 'mois': 'FEVRIER', 'annee': '2023', 'titre': ''}\n",
      "Identifiant part : AR2023-044\n",
      "Date decision part : 2023-02-03\n",
      "Identifiant part : \n",
      "Date decision part : \n",
      "Identifiant part : \n",
      "Date decision part : \n",
      "Identifiant final :  AR2023-044\n",
      "Titre final :  Arrêté n°AR 2023-044 Portant délégations de signatures du pôle politiques sportives, de santé, de solidarité et de sécurité (PS4)\n",
      "Date décision finale :  2023-02-03\n",
      " =====OCR===== \n",
      "DEBUT DOC AR2023-045.pdf\n",
      "Texte replace / :  Envoyé en préfecture le 06022023 Reçu en préfecture le 06022023\n",
      "Texte replace / :  Publié le S L O7\n",
      "Texte replace / :  ID : 075-237500079-20230206-2023 045-AR\n",
      "Texte replace / :   \n",
      "Texte replace / :  Me Région\n",
      "Texte replace / :  ileceFrance ARRETE N°2023-045 DU 6 FEVRIER 2023\n",
      "Identifiant trouvé :  ileceFrance ARRETE N°2023-045 DU 6 FEVRIER 2023\n",
      "Match :  {'numero': '2023-045 ', 'jour': '6', 'mois': 'FEVRIER', 'annee': '2023', 'titre': ''}\n",
      "Identifiant part : AR2023-045\n",
      "Date decision part : 2023-02-06\n",
      "Identifiant part : \n",
      "Date decision part : \n",
      "Identifiant final :  AR2023-045\n",
      "Titre final :  Arrêté n°AR 2023-045 DE CESSION VEHICULES FEVRIER 2023\n",
      "Date décision finale :  2023-02-06\n"
     ]
    }
   ],
   "source": [
    "# Traitement principal\n",
    "liste_avant_identifiants = []\n",
    "for fichier in liste_fichier:\n",
    "    dictionnaire = traite_fichier_arrete(fichier, verbose=False)\n",
    "    liste_avant_identifiants.append(dictionnaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "aac1251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste_avant_identifiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e672a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names_csv = ['coll_nom','coll_siret','identifiant','numero','titre', 'type_acte', 'type', 'type_seance', 'theme',\n",
    "                   'date_controle','date_decision',\n",
    "                   'date_publication','date_affichage',\n",
    "                   'texte_arrete','messages','nom_fichier',\n",
    "                   'url1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "56d8cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dictionnaire = {\"coll_nom\": \"coll_nom\",\n",
    "                    \"coll_siret\": \"coll_siret\",\n",
    "                    \"identifiant\": \"identifiant\",\n",
    "                    \"numero\": \"numero\",\n",
    "                    \"titre\": \"titre\",\n",
    "                    \"type_acte\": \"type_acte\",\n",
    "                    \"type\": \"type\",\n",
    "                    \"type_seance\": \"type_seance\",\n",
    "                    \"theme\": \"theme\",\n",
    "                    \"date_controle\": \"date_controle\",\n",
    "                    \"date_decision\": \"date_decision\",\n",
    "                    \"date_publication\": \"date_publication\",\n",
    "                    \"date_affichage\": \"date_affichage\",\n",
    "                    \"texte_arrete\": \"texte_arrete\",\n",
    "                    \"messages\": \"messages\",\n",
    "                    \"nom_fichier\": \"nom_fichier\",\n",
    "                    \"url1\": \"url1\"\n",
    "                   }\n",
    "\n",
    "append_dict_as_row(fichier_a_inscrire, dictionnaire, field_names_csv)\n",
    "\n",
    "for dictionnaire in liste_avant_identifiants:\n",
    "    append_dict_as_row(fichier_a_inscrire, dictionnaire, field_names_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97197e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32ebcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste_arrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f3cf8",
   "metadata": {},
   "source": [
    "# Récupérer les délibs déjà publiées en open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94db7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL API permettant de récupérer les délibérations déjà publiées\n",
    "url_api_opendata_delibs = \"https://data.iledefrance.fr/api/records/1.0/search/?dataset=actes-administratifs&q=&rows=10000&facet=type_acte&facet=type&facet=theme&facet=type_seance&refine.type_acte=AR&apikey=70b1e8b9be88b35fd29c3706bf258b3b6c9071ffa4e32504793e395b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8c04ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requête de l'API Opendatasoft\n",
    "response_API = requests.get(url_api_opendata_delibs)\n",
    "data = response_API.text\n",
    "parse_json = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "974f1cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code de réponse de l'API :  200\n",
      "Nombre d'arrêtés déjà publiés en open data :  1377\n"
     ]
    }
   ],
   "source": [
    "# Nombre de délibérations trouvées: parse_json['nhits']\n",
    "\n",
    "# Arbre des résultats: parse_json['records']\n",
    "\n",
    "# Pour chaque entrée des résultats:\n",
    "# Timestamp de l'entrée: parse_json['records']['record_timestamp']\n",
    "# Accès aux champs de l'entée: parse_json['records']['fields']\n",
    "# Champs identifiant de l'entée: parse_json['records']['fields']['identifiant']\n",
    "# Champ date_publication de l'entée: parse_json['records']['fields']['date_publication']\n",
    "\n",
    "dictionnaire_delibs_opendata = {}\n",
    "for record in parse_json['records']:\n",
    "    dictionnaire_delibs_opendata[record['fields']['identifiant']] = {\n",
    "        'identifiant': record['fields']['identifiant'],\n",
    "        'timestamp': record['record_timestamp'],\n",
    "        'date_publication':record['fields']['date_publication']\n",
    "    }\n",
    "\n",
    "print(\"Code de réponse de l'API : \", response_API.status_code)\n",
    "print(\"Nombre d'arrêtés déjà publiés en open data : \", parse_json['nhits'])\n",
    "# print(\"Dictionnaire des délibérations publiées en open data : \", dictionnaire_delibs_opendata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "799bc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lister les délibérations qui sont déjà publiées en open data et vont être exclues\n",
    "liste_delibs_a_exclure = []\n",
    "for dictionnaire in liste_avant_identifiants:\n",
    "    if (dictionnaire['identifiant'] != \"\"):\n",
    "        if (dictionnaire['identifiant'] in dictionnaire_delibs_opendata):\n",
    "            print(\"Identifiant déjà publié en open data : \", dictionnaire['identifiant'], \" ; date initiale de publication : \", dictionnaire_delibs_opendata[dictionnaire['identifiant']]['date_publication'])\n",
    "            liste_delibs_a_exclure.append(dictionnaire['identifiant'])\n",
    "        else:\n",
    "            continue\n",
    "            print(\"Délibération non encore publiée: \", dictionnaire['identifiant'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6836bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a857f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b17907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6e0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
